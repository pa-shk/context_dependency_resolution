model_name: "ai-forever/ruT5-base"
training_args:
  eval_strategy: "epoch"
  learning_rate: 2e-4
  batch_size: 16
  gradient_accumulation_steps: 16
  weight_decay: 0.01
  save_total_limit: 3
  num_train_epochs: 50
  predict_with_generate: true
  fp16: false
  push_to_hub: false
  logging_steps: 10
  overwrite_output_dir: true
inference_args:
 max_length: 50
 num_beams: 2
 early_stopping: true
 skip_special_tokens: true
 clean_up_tokenization_spaces: true